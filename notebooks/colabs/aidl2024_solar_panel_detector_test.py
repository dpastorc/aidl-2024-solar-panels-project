# -*- coding: utf-8 -*-
"""AIDL2024_Solar_Panel_Detector_Test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lSjcyAMdD-31aPOu0LLpOEguHUDia404

# AIDL 2024 - Solar Panel Detector Project: **Test** (step 3/4)


Notebook created for the Postgraduate course in artificial intelligence with deep learning in UPC School (2024).
Project members: Manel Toril, Raphael Gagliardi, David Pastor and Daniel Domingo. Supervisor: Amanda Duarte.

The purpose of this notebook is to run test (inference) using an AI model trained on a given dataset, and retrieve key metrics such as Dice score and Jaccard index to compare with train and evaluation metrics, in order to assess the quality of the model.

## How to run this code:

1. Under **Quick Configuration**:
*   Update **dataset_name** to select the desired dataset
*   Update **model_sel** to select the desired trained model from the two available: *UNet* or *Segformer*
*   Update **dict_sel** to select the desired dictionary to initialize the model

2. Choose a T4 GPU environment.

3. Execute all cells in the notebook from top, in sequential order

4. Download the resulting zip file to your local storage. This zip contains an image with samples of images, masks and overlay.

# Quick configuration
"""

# Quick configuration
dataset_name = 'ZENODO-split'                                                   # Datasets available: PV01-split, PV-ALL-split, PV03-CROP-split, ZENODO-split
model_sel = 'Segformer'                                                         # Segformer or UNet
dict_sel = 'segformer_solar_panel_detector.pth'                                 # Dictionary of the selected fine-tuned model for solar panel detection

"""# Parameters"""

# Dataset parameters
pv_file_format = 'bmp'                                                          # File format within the PVXX dataset
google_file_format = 'png'                                                      # File format within the Google dataset
dataset_url = 'https://temp-posgraduation.s3.amazonaws.com/' + dataset_name + '.zip' # Location of the preprocessed and split dataset
root_dir = '/content/'                                                          # Root directory
dataset_path = root_dir + 'dataset/'                                            # Path to the dataset
test_image_dir = dataset_path + 'test/images'                                   # Test dataset path - images
test_mask_dir = dataset_path + 'test/masks'                                     # Test dataset path - masks

# Inference parameters
batch_size = 8                                                                  # 8 on T4 GPU, 64 on A100 GPU
image_size = 256                                                                # Image size for inference
output_dir = root_dir + 'results/'                                              # Path to the output directory
results_path = output_dir + 'test_results.txt'                                  # Path to the results file

# Model parameters
model_dir = root_dir + 'model/'                                                 # Path to the pretrained model dictionary folder
pretrained_model_path = model_dir + dict_sel                                    # Path to the pretrained model dictionary
dict_location = 'https://temp-posgraduation.s3.amazonaws.com/'                  # Base public URL where pretrained model dictionaries have been placed for download

# Segformer model parameters
seg_pretrained_model_name = "nvidia/segformer-b0-finetuned-ade-512-512"         # Pretrained Segformer
id2label = {0: 'background', 1: 'solar_panel'}                                  # dictionary of solar paner labels
label2id = {label: id for id, label in id2label.items()}                        # dictionary to load the segformer
num_labels = len(id2label)                                                      # parameter to load the segformer

# Zip parameters
zip_filename = 'Solar_Panel_Detector_Test.zip'                                  # Name of the zip file to save the experiment outputs
exclude_folders = ['sample_data', 'dataset', 'model', '.config', zip_filename]  # Paths to exclude in zip file

"""# Libraries"""

# Import libraries - TBD

import os
import matplotlib.pyplot as plt
import numpy as np
import random
import shutil
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms.functional as TF
import zipfile
import requests

from google.colab import files
from PIL import Image, ImageEnhance, ImageFilter, ImageDraw
from sklearn.metrics import accuracy_score, jaccard_score, f1_score
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from transformers import SegformerForSemanticSegmentation
from tqdm import tqdm

"""# Supporting Functions

**Function to calculate execution times**
"""

# Function to calculate execution times

def format_time(elapsed_time) -> str:
    days = 0
    if elapsed_time >= 86400:
        days = int(elapsed_time / 86400)
    elapsed_str = time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
    return str(days) + ":" + elapsed_str

"""**Functions to manage files and folders**"""

# Delete desired folders
paths_to_remove = "/content/results /content/dataset"   # "/content/samples /content/plots /content/sample_data /content/model"
# !rm -rf {paths_to_remove}

# Function to zip folders considering exclusion list

def zip_dir(dir_to_zip, output_zip, exclude=[]):
    exclude = [os.path.abspath(os.path.join(dir_to_zip, ex_folder)) for ex_folder in exclude]
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # Iterate over all files and folders in the directory
        for root, _, files in os.walk(dir_to_zip):
            abs_root = os.path.abspath(root)
            # Check if the current root is in the exclude list
            if any(abs_root.startswith(ex_folder) for ex_folder in exclude):
                continue  # Skip this folder and its contents if in exclude list

            for file in files:
                if file == os.path.basename(output_zip):
                    continue  # Skip the output zip file itself
                abs_file = os.path.join(root, file)
                zipf.write(abs_file, os.path.relpath(abs_file, dir_to_zip))


# Function to list folders within a zip file

def list_folders_and_files_in_zip(zip_file):
    with zipfile.ZipFile(zip_file, 'r') as zipf:
        file_set = set()

        # Iterate over each entry in the zip file
        for entry in zipf.infolist():
            entry_name = entry.filename

            # Determine if entry is a directory or file
            if entry_name.endswith('/'):
                # Entry is a directory
                folder_name = entry_name.rstrip('/')
            else:
                # Entry is a file
                file_set.add(entry_name)

        print("Files in the zip file:")
        for file in file_set:
            print(file)

"""**Functions to generate and save images**"""

# Function to create an overlay of image and mask

def overlay_image(image, mask, color, alpha, resize=None):
    im_copy = (image * 255).astype(np.uint8)
    im_copy = Image.fromarray(im_copy, "RGB")

    if resize:
        im_copy = im_copy.resize(resize)
        mask = Image.fromarray((mask * 128).astype(np.uint8)).resize(resize)
    else:
        mask = Image.fromarray((mask * 128).astype(np.uint8))

    full_color = Image.new("RGB", im_copy.size, color)
    im_copy = Image.composite(full_color, im_copy, mask)
    return np.array(im_copy)

# Function to save samples

def save_samples(images, masks, predictions, sample_type, output_dir="results", num_samples=8):
    os.makedirs(output_dir, exist_ok=True)

    # Ensure num_samples is not larger than the length of images, masks, or predictions
    num_samples = min(num_samples, len(images), len(masks), len(predictions))

    if num_samples == 0:
        print("No samples to display")
        return

    fig, axes = plt.subplots(nrows=num_samples, ncols=4, figsize=(16, 4 * num_samples))

    # Generate random indices to select random samples
    indices = random.sample(range(len(images)), num_samples)

    # Ensure axes is a 2D array even if num_samples is 1
    if num_samples == 1:
        axes = np.expand_dims(axes, axis=0)

    for i, idx in enumerate(indices):
        if images[idx] is not None and images[idx].ndim == 3:
            img = images[idx].cpu().permute(1, 2, 0).numpy()
            img = img.clip(0, 1)  # Clip values to the range [0, 1]
            axes[i, 0].imshow(img)  # Original image
            axes[i, 0].set_title("Image")
        else:
            print(f"Warning: Image at index {idx} is not valid for visualization.")
            axes[i, 0].axis('off')

        if masks[idx] is not None and masks[idx].ndim == 2:
            mask = masks[idx].cpu().numpy()
            axes[i, 1].imshow(mask, cmap='gray', vmin=0, vmax=1)  # Ground truth mask
            axes[i, 1].set_title("Mask")
        else:
            print(f"Warning: Mask at index {idx} is not valid for visualization.")
            axes[i, 1].axis('off')

        if predictions[idx] is not None and predictions[idx].ndim == 2:
            pred = predictions[idx].cpu().numpy()
            axes[i, 2].imshow(pred, cmap='gray', vmin=0, vmax=1)  # Predicted mask
            axes[i, 2].set_title("Prediction")

            # Overlapped predicted mask and original
            if images[idx] is not None and images[idx].ndim == 3:
                image_with_masks = overlay_image(img, pred, color=(0, 255, 0), alpha=0.3)
                axes[i, 3].imshow(image_with_masks)
                axes[i, 3].set_title('Overlap')
            else:
                axes[i, 3].axis('off')
        else:
            print(f"Warning: Prediction at index {idx} is not valid for visualization.")
            axes[i, 2].axis('off')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"{sample_type}_samples.png"))
    plt.close()

"""# Dataset download function"""

# Function to download and extract the dataset

def download_and_extract(url, dest_path):
    if not os.path.exists(dest_path):
        os.makedirs(dest_path)

    dataset_zip = os.path.join(dest_path, 'dataset.zip')

    if not os.path.exists(dataset_zip):
        print("Downloading dataset...")
        r = requests.get(url, stream=True)
        with open(dataset_zip, 'wb') as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
        print("Download complete.")

    if dataset_zip.endswith('.zip'):
        print("Extracting dataset...")
        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
            zip_ref.extractall(dest_path)
        print("Extraction complete.")

        # Delete the zip file after extraction
        os.remove(dataset_zip)
        print(f"Deleted {dataset_zip} after extraction.")

"""# Model, dataset class and test functions

**UNet model**
"""

#Unet - Full 1024
class UNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(UNet, self).__init__()
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        self.bottleneck = self.conv_block(512, 1024)
        self.upconv4 = self.upconv(1024, 512)
        self.dec4 = self.conv_block(1024, 512)
        self.upconv3 = self.upconv(512, 256)
        self.dec3 = self.conv_block(512, 256)
        self.upconv2 = self.upconv(256, 128)
        self.dec2 = self.conv_block(256, 128)
        self.upconv1 = self.upconv(128, 64)
        self.dec1 = self.conv_block(128, 64)
        self.conv_out = nn.Conv2d(64, out_channels, kernel_size=1)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def upconv(self, in_channels, out_channels):
        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)

    def forward(self, x):
        enc1 = self.enc1(x)
        enc2 = self.enc2(F.max_pool2d(enc1, 2))
        enc3 = self.enc3(F.max_pool2d(enc2, 2))
        enc4 = self.enc4(F.max_pool2d(enc3, 2))
        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))
        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.dec4(dec4)
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.dec3(dec3)
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.dec2(dec2)
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.dec1(dec1)
        out = self.conv_out(dec1)
        return out

"""**Model dictionary download function**"""

# Function to download the pretrained model dictionary
def download_dict(base_url, model_dir, filename):
    url = os.path.join(base_url, filename)
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    file_path = os.path.join(model_dir, filename)
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad status codes
        with open(file_path, 'wb') as f:
            f.write(response.content)
    except requests.exceptions.RequestException as e:
        print(f"Error downloading the dictionary: {e}")

"""**Dataset class**"""

class SolarPanelTestDataset(Dataset):
    def __init__(self, image_dir, mask_dir, file_format, transforms=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transforms = transforms
        self.file_format = file_format
        self.images = os.listdir(image_dir)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.image_dir, img_name)

        # Adjust mask file name to consider the specified format
        mask_name = img_name.replace(f'.{self.file_format}', f'_label.{self.file_format}')
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")
        mask = mask.point(lambda p: p > 80 and 255)

        if self.transforms:
            image = self.transforms(image)
            mask = self.transforms(mask)

        mask = torch.tensor(np.array(mask, dtype=np.uint8), dtype=torch.long)
        mask = mask.squeeze()

        return image, mask

"""**Test function**"""

def test_model(model_sel, model, image_dir, mask_dir, output_dir, results_path, dataset_name, image_size):

    # Transformations for the dataset
    transform_images = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
    ])

    # Set file_format
    if dataset_name.startswith("PV"):
        file_format = pv_file_format
    else:
        file_format = google_file_format

    # Create dataset
    test_dataset = SolarPanelTestDataset(image_dir=image_dir, mask_dir=mask_dir, file_format=file_format, transforms=transform_images)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)

    # Set criterion
    if model_sel == "Segformer":
        criterion = nn.CrossEntropyLoss()
    else:
        criterion = nn.BCEWithLogitsLoss()

    # Test
    model.eval()
    test_loss = 0.0
    test_accuracy = 0.0
    all_dice_scores = []
    all_jaccard_indices = []

    with torch.no_grad():
        test_loader_tqdm = tqdm(test_loader, desc="Test")

        for batch_idx, (images, masks) in enumerate(test_loader_tqdm):
            images = images.to(device)
            masks = masks.to(device)

            if model_sel == "Segformer":
                  outputs = model(pixel_values=images).logits
                  outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False)
                  outputs = outputs.permute(0, 2, 3, 1).reshape(-1, outputs.size(1)) # (N, C, H, W) -> (N*H*W, C)
                  masks = masks.reshape(-1) # (N, H, W) -> (N*H*W)
                  _, predicted = torch.max(outputs, 1)
                  loss = criterion(outputs, masks.long())
                  test_loss += loss.item()
                  # Calculate metrics
                  accuracy = accuracy_score(masks.cpu().numpy(), predicted.cpu().numpy())
                  test_accuracy += accuracy
                  dice_score = f1_score(masks.cpu().numpy(), predicted.cpu().numpy(), average='binary', zero_division=0)
                  jaccard_index = jaccard_score(masks.cpu().numpy(), predicted.cpu().numpy(), average='binary', zero_division=0)
            elif model_sel == "UNet":
                  outputs = model(images)
                  outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False)
                  outputs = outputs.squeeze(1)
                  preds = torch.sigmoid(outputs)
                  predicted = (preds > 0.5).float()
                  if predicted.shape != masks.shape:
                    predicted = predicted.view(masks.shape[0], masks.shape[1], masks.shape[2])
                  loss = criterion(outputs, masks.float())  # BCEWithLogitsLoss requires float
                  test_loss += loss.item()
                  # Calculate metrics
                  accuracy = accuracy_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy())
                  test_accuracy += accuracy
                  dice_score = f1_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy(), average='binary', zero_division=0)
                  jaccard_index = jaccard_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy(), average='binary', zero_division=0)
            else:
                print("Error: Invalid model selection.")

            # Append metrics
            all_dice_scores.append(dice_score)
            all_jaccard_indices.append(jaccard_index)

            test_loader_tqdm.set_postfix({"loss": loss.item(), "accuracy": accuracy, "f1-score": dice_score, "jaccard-index": jaccard_index})

    # Save test samples
    save_samples(images, masks.reshape(images.shape[0], image_size, image_size), predicted.reshape(images.shape[0], image_size, image_size), sample_type="test", output_dir=output_dir)
    print(f"Saved test samples")

    avg_test_loss = test_loss / len(test_loader)
    avg_test_accuracy = test_accuracy / len(test_loader)
    avg_dice_score = sum(all_dice_scores) / len(all_dice_scores)
    avg_jaccard_index = sum(all_jaccard_indices) / len(all_jaccard_indices)

    print(f"Test: Avg Test Loss: {avg_test_loss:.4f}")
    print(f"Test: Avg Test Accuracy: {avg_test_accuracy:.4f}")
    print(f"Test: Avg Dice Score: {avg_dice_score:.4f}, Avg Jaccard Index: {avg_jaccard_index:.4f}")

    # Write results to text file
    with open(results_path, 'w') as file:
        file.write(f'Model: {model_sel} with {dict_sel}\n')
        file.write(f'Average Test Loss: {avg_test_loss}\n')
        file.write(f'Average Test Accuracy: {avg_test_accuracy}\n')
        file.write(f'Average Dice Score: {avg_dice_score}\n')
        file.write(f'Average Jaccard Index: {avg_jaccard_index}\n')
        print(f"Results saved to {results_path}")
    return avg_test_loss, avg_test_accuracy, avg_dice_score, avg_jaccard_index

"""# Execution

**Download dataset**
"""

# Download and extract the dataset
start_time = time.perf_counter()
download_and_extract(dataset_url, dataset_path)
test_images_count = len(os.listdir(test_image_dir))                             # Count the number of images under test folder
print(f"Number of images in the test set: {test_images_count}")
elapsed_time = time.perf_counter() - start_time
print(f"Download & extract took: {format_time(elapsed_time)}")

"""**Load the model**"""

# Load selected model
if model_sel == "Segformer":
    print("Loading Segformer...")
    # Load the pretrained Segformer model
    model = SegformerForSemanticSegmentation.from_pretrained(
        seg_pretrained_model_name,
        num_labels=num_labels,
        id2label=id2label,
        label2id=label2id,
        ignore_mismatched_sizes=True,
    )
elif model_sel == "UNet":
    print("Loading UNet...")
    # Load the pretrained UNet model
    model = UNet(in_channels=3, out_channels=1)
else:
    print("Error: Invalid model selection")

# Download and load the state dictionary from a pretrained model
download_dict(dict_location, model_dir, dict_sel)
try:
    model.load_state_dict(torch.load(pretrained_model_path))
    print(f"Successfully loaded the model from {pretrained_model_path}")
except Exception as e:
    print(f"Error loading the model from {pretrained_model_path}: {e}")

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""**Run test**"""

# Run test
start_time = time.perf_counter()
print(f"Running test")
test_model(model_sel, model, image_dir=test_image_dir, mask_dir=test_mask_dir, output_dir=output_dir, results_path=results_path, dataset_name=dataset_name, image_size=image_size)
elapsed_time = time.perf_counter() - start_time
print(f"Test took: {format_time(elapsed_time)}\n")

"""**Zip results**"""

# Create the zip file
zip_dir(root_dir, zip_filename, exclude_folders)
zip_file_path = os.path.join(root_dir, zip_filename)
list_folders_and_files_in_zip(zip_file_path)