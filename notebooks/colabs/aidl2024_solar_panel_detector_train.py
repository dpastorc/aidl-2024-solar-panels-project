# -*- coding: utf-8 -*-
"""AIDL2024_Solar_Panel_Detector_Train.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YMNjZy9wRmxvPhi7v1RSRhV88ojhIP4k

# AIDL 2024 - Solar Panel Detector Project: **Training and Validation** (step 2/4)


Notebook created for the Postgraduate course in artificial intelligence with deep learning in UPC School (2024).
Project members: Manel Toril, Raphael Gagliardi, David Pastor and Daniel Domingo. Supervisor: Amanda Duarte.

The purpose of this notebook is to train an AI model on a given pre-processed dataset, and retrieve key metrics such as Dice score and Jaccard index, comparing with evaluation steps aiming to maximize metrics through iterative experiments.

## How to run this code:

**Quick Configuration**:
1. Under **Quick Configuration and Hyperparameters**:
*   Update **dataset_name** to select the desired dataset
*   Update **model_sel** to select the desired trained model from the two available: *UNet* or *Segformer*
*   Update **seg_pretrained_model_name** to select the desired Segformer version (from b0 to b5). Ignore for UNet selection.
*   Update **dict_sel** to select the desired dictionary to initialize the model
*   Update **batch_size** to 64 if an A100 GPU is available, otherwise fall back to 8 for T4 GPU
*   Update **image_size** to train with different image sizes (warning: training with 400px from the Google dataset increases training time considerably)
*   Update **num_epochs** as desired based on experiment
*   Update **val_interval** as desired based on experiment (set higher as num_epochs increases)
*   Update **lr** to the desired learning rate (starting value if early_stop mehcanism is on)

2. Under **Learning Rate Hyperparameter Optimization**:
*   Update **early_stop** to True or False if you are performing learning rate hyperparameter optimization
*   Update **early_stop_patience** with the desired number of epochs without validation loss improvement that will trigger early stop

2. Choose A100 GPU environment if available (fall back to T4 GPU otherwise)

3. Execute all cells in the notebook from top, in sequential order

4. Download the resulting zip file to your local storage. This zip contains an image with samples of images, masks and overlay.

# Quick configuration
"""

# Quick configuration and Hyperparameters
dataset_name = 'ZENODO-split'                                                   # Datasets available: PV01-split, PV-ALL-split, PV03-CROP-split, ZENODO-split
model_sel = 'Segformer'                                                         # Segformer or UNet
seg_pretrained_model_name = "nvidia/segformer-b0-finetuned-ade-512-512"         # Pretrained Segformer model range from b0 to b5. Ignore for UNet selection
dict_sel = None                                                                 # Dictionary of the selected fine-tuned model from previous iterations; Use None to train from scratch.
batch_size = 64                                                                 # 8 on T4 GPU, 64 on A100 GPU
image_size = 256                                                                # Image size for training
num_epochs = 50                                                                 # Train epochs
val_interval = 5                                                                # Epochs interval to execute validation cycles
lr = 0.0001                                                                     # Subject to fine-tuning (1e-4 found stable)

# Learning Rate Hyperparameter Optimization
early_stop = False                                                              # Early stopping: True or False
early_stop_patience = 10                                                        # Number of epochs to wait after the last improvement before stopping the training

# Data augmentation
data_augmentation_flip = True                                                   # Data augmentation - random horizontal and/or vertical flip
data_augmentation_rotation = True                                               # Data augmentation - random rotation in 90 degrees steps
data_augmentation_brightness = True                                             # Data augmentation - random brigthness adjustment
data_augmentation_contrast = True                                               # Data augmentation - random contrast adjustment
data_augmentation_saturation = True                                             # Data augmentation - random saturation adjustment
data_augmentation_hue = True                                                    # Data augmentation - random hue adjustment
data_augmentation_blur = True                                                   # Data augmentation - blur
data_augmentation_sharpen = True                                                # Data augmentation - sharpen
data_augmentation_gaussian_noise = True                                         # Data augmentation - noise
data_augmentation_random_padding = True                                         # Data augmentation - random black or white padding (replacing part of the image, between 10% and 50%)
data_augmentation_random_polygons = True                                        # Data augmentation - random black or white polygons (square, rectangle between 5 and 20%, and L shapes between 5 and 15%)
data_augmentation_contain_solar_panel = False                                   # Perform data augmentation on imgs that contain solar panels only (True on PV03, False on PV01 and ZENODO)

"""# Other parameters and paths"""

# Dataset parameters
pv_file_format = 'bmp'                                                          # File format within the PVXX dataset
google_file_format = 'png'                                                      # File format within the Google dataset
dataset_url = 'https://temp-posgraduation.s3.amazonaws.com/' + dataset_name + '.zip' # Location of the preprocessed and split dataset
root_dir = '/content/'                                                          # Root directory
dataset_path = root_dir + 'dataset/'                                            # Path to the dataset
train_image_dir = dataset_path + 'train/images'                                 # Train dataset path - images
train_mask_dir = dataset_path + 'train/masks'                                   # Train dataset path - masks
val_image_dir = dataset_path + 'val/images'                                     # Validation dataset path - images
val_mask_dir = dataset_path + 'val/masks'                                       # Validation dataset path - masks

# Training parameters
num_samples = 10                                                                # Number of train and validation samples to save
output_dir = root_dir + 'results/'                                              # Path to the output results directory
results_path = output_dir + 'test_results.txt'                                  # Path to the results file

# Model parameters
model_dir = root_dir + 'model/'                                                 # Path to the pretrained model dictionary folder
dict_location = 'https://temp-posgraduation.s3.amazonaws.com/'                  # Base public URL where pretrained model dictionaries have been placed for download
model_name = 'solar_panel_detector_train.pth'                                   # Name of the trained model dictionary to save

# Segformer model parameters
id2label = {0: 'background', 1: 'solar_panel'}                                  # dictionary of solar paner labels
label2id = {label: id for id, label in id2label.items()}                        # dictionary to load the segformer
num_labels = len(id2label)                                                      # parameter to load the segformer

# Zip parameters
zip_filename = 'Solar_Panel_Detector_Train.zip'                                  # Name of the zip file to save the experiment outputs
exclude_folders = ['sample_data', 'dataset', 'model', '.config', zip_filename]  # Paths to exclude in zip file

"""# Libraries"""

# Import libraries - TBD

import os
import matplotlib.pyplot as plt
import numpy as np
import random
import shutil
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision.transforms.functional as TF
import zipfile
import requests

from PIL import Image, ImageEnhance, ImageFilter, ImageDraw
from sklearn.metrics import accuracy_score, jaccard_score, f1_score
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from transformers import SegformerForSemanticSegmentation
from tqdm import tqdm
from scipy.ndimage import gaussian_filter
from torch.optim.lr_scheduler import ReduceLROnPlateau

"""# Supporting Functions

**Function to calculate execution times**
"""

# Function to calculate execution times

def format_time(elapsed_time) -> str:
    days = 0
    if elapsed_time >= 86400:
        days = int(elapsed_time / 86400)
    elapsed_str = time.strftime("%H:%M:%S", time.gmtime(elapsed_time))
    return str(days) + ":" + elapsed_str

"""**Functions to manage files and folders**"""

# Delete desired folders
paths_to_remove = "/content/results /content/samples /content/plots"   # "/content/samples /content/plots /content/sample_data /content/model"
# !rm -rf {paths_to_remove}

# Function to zip folders considering exclusion list

def zip_dir(dir_to_zip, output_zip, exclude=[]):
    exclude = [os.path.abspath(os.path.join(dir_to_zip, ex_folder)) for ex_folder in exclude]
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        # Iterate over all files and folders in the directory
        for root, _, files in os.walk(dir_to_zip):
            abs_root = os.path.abspath(root)
            # Check if the current root is in the exclude list
            if any(abs_root.startswith(ex_folder) for ex_folder in exclude):
                continue  # Skip this folder and its contents if in exclude list

            for file in files:
                if file == os.path.basename(output_zip):
                    continue  # Skip the output zip file itself
                abs_file = os.path.join(root, file)
                zipf.write(abs_file, os.path.relpath(abs_file, dir_to_zip))


# Function to list folders within a zip file

def list_folders_and_files_in_zip(zip_file):
    with zipfile.ZipFile(zip_file, 'r') as zipf:
        file_set = set()

        # Iterate over each entry in the zip file
        for entry in zipf.infolist():
            entry_name = entry.filename

            # Determine if entry is a directory or file
            if entry_name.endswith('/'):
                # Entry is a directory
                folder_name = entry_name.rstrip('/')
            else:
                # Entry is a file
                file_set.add(entry_name)

        print("Files in the zip file:")
        for file in file_set:
            print(file)

"""**Functions to generate and save images**"""

# Function to create an overlay of image and mask

def overlay_image(image, mask, color, alpha, resize=None):
    im_copy = (image * 255).astype(np.uint8)
    im_copy = Image.fromarray(im_copy, "RGB")

    if resize:
        im_copy = im_copy.resize(resize)
        mask = Image.fromarray((mask * 128).astype(np.uint8)).resize(resize)
    else:
        mask = Image.fromarray((mask * 128).astype(np.uint8))

    full_color = Image.new("RGB", im_copy.size, color)
    im_copy = Image.composite(full_color, im_copy, mask)
    return np.array(im_copy)

# Function to save samples

def save_samples(images, masks, predictions, epoch, sample_type, output_dir="results", num_samples=8):
    os.makedirs(output_dir, exist_ok=True)

    # Ensure num_samples is not larger than the length of images, masks, or predictions
    num_samples = min(num_samples, len(images), len(masks), len(predictions))

    if num_samples == 0:
        print("No samples to display")
        return

    fig, axes = plt.subplots(nrows=num_samples, ncols=4, figsize=(16, 4 * num_samples))

    # Generate random indices to select random samples
    indices = random.sample(range(len(images)), num_samples)

    # Ensure axes is a 2D array even if num_samples is 1
    if num_samples == 1:
        axes = np.expand_dims(axes, axis=0)

    for i, idx in enumerate(indices):
        if images[idx] is not None and images[idx].ndim == 3:
            img = images[idx].cpu().permute(1, 2, 0).numpy()
            img = img.clip(0, 1)  # Clip values to the range [0, 1]
            axes[i, 0].imshow(img)  # Original image
            axes[i, 0].set_title("Image")
        else:
            print(f"Warning: Image at index {idx} is not valid for visualization.")
            axes[i, 0].axis('off')

        if masks[idx] is not None and masks[idx].ndim == 2:
            mask = masks[idx].cpu().numpy()
            axes[i, 1].imshow(mask, cmap='gray', vmin=0, vmax=1)  # Ground truth mask
            axes[i, 1].set_title("Mask")
        else:
            print(f"Warning: Mask at index {idx} is not valid for visualization.")
            axes[i, 1].axis('off')

        if predictions[idx] is not None and predictions[idx].ndim == 2:
            pred = predictions[idx].cpu().numpy()
            axes[i, 2].imshow(pred, cmap='gray', vmin=0, vmax=1)  # Predicted mask
            axes[i, 2].set_title("Prediction")

            # Overlapped predicted mask and original
            if images[idx] is not None and images[idx].ndim == 3:
                image_with_masks = overlay_image(img, pred, color=(0, 255, 0), alpha=0.3)
                axes[i, 3].imshow(image_with_masks)
                axes[i, 3].set_title('Overlap')
            else:
                axes[i, 3].axis('off')
        else:
            print(f"Warning: Prediction at index {idx} is not valid for visualization.")
            axes[i, 2].axis('off')

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f"epoch_{epoch+1}_{sample_type}_samples.png"))
    plt.close()

# Function to calculate epochs where samples will be saved

def calculate_save_epochs(num_epochs, val_interval, num_samples):

    # Ensure num_epochs and val_interval are valid
    if num_epochs <= 0:
        raise ValueError("num_epochs must be a positive integer")
    if val_interval <= 0:
        raise ValueError("val_interval must be a positive integer")

    # Calculate the epochs where validation occurs based on the validation interval
    validation_epochs = list(range(val_interval - 1, num_epochs, val_interval))

    # Ensure the first and last epochs are included in the save_epochs
    if 0 not in validation_epochs:
        validation_epochs.insert(0, 0)
    if num_epochs - 1 not in validation_epochs:
        validation_epochs.append(num_epochs - 1)

    # If we have more than the desired number of samples, downsample to the desired number
    if len(validation_epochs) > num_samples:
        save_epochs = np.linspace(0, len(validation_epochs) - 1, num=num_samples, dtype=int)
        save_epochs = [validation_epochs[i] for i in save_epochs]
    else:
        save_epochs = validation_epochs

    return save_epochs

"""**Function to plot loss, validation and accuracy charts, and IoU and F1 Score charts**"""

# Function to plot loss, validation and accuracy charts, and IoU and F1 Score charts

def plot_charts(train_losses, train_accuracies, val_losses, val_accuracies, ious, f1s, val_interval):
    epochs = len(train_losses)
    val_epochs = range(val_interval, epochs + 1, val_interval)

    plt.figure(figsize=(12, 12))

    # Plot Training and Validation Loss
    plt.subplot(2, 2, 1)
    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')
    plt.plot(val_epochs, val_losses, label='Val Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)

    # Plot Training and Validation Accuracy
    plt.subplot(2, 2, 2)
    plt.plot(range(1, epochs + 1), train_accuracies, label='Train Accuracy')
    plt.plot(val_epochs, val_accuracies, label='Val Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend()
    plt.grid(True)

    # Plot IoU and F1 Score
    plt.subplot(2, 2, 3)
    plt.plot(val_epochs, ious, label='IoU')
    plt.plot(val_epochs, f1s, label='F1')
    plt.xlabel('Epochs')
    plt.ylabel('Score')
    plt.title('Validation IoU and F1 Score')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

# Function to save plots
def save_plots(train_losses, train_accuracies, val_losses, val_accuracies, ious, f1s, val_interval, epoch=None, output_dir="plots"):
    os.makedirs(output_dir, exist_ok=True)
    epochs = len(train_losses)
    val_epochs = range(val_interval, epochs + 1, val_interval)

    plt.figure(figsize=(12, 12))

    # Plot Training and Validation Loss
    plt.subplot(2, 2, 1)
    plt.plot(range(1, epochs + 1), train_losses, label='Train Loss')
    plt.plot(val_epochs, val_losses, label='Val Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()
    plt.grid(True)

    # Plot Training and Validation Accuracy
    plt.subplot(2, 2, 2)
    plt.plot(range(1, epochs + 1), train_accuracies, label='Train Accuracy')
    plt.plot(val_epochs, val_accuracies, label='Val Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Training and Validation Accuracy')
    plt.legend()
    plt.grid(True)

    # Plot IoU and F1 Score
    plt.subplot(2, 2, 3)
    plt.plot(val_epochs, ious, label='IoU')
    plt.plot(val_epochs, f1s, label='F1')
    plt.xlabel('Epochs')
    plt.ylabel('Score')
    plt.title('Validation IoU and F1 Score')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    if epoch is not None:
        plt.savefig(os.path.join(output_dir, f'loss_and_scores_epoch_{epoch + 1}.png'))
    else:
        plt.savefig(os.path.join(output_dir, 'loss_and_scores_final.png'))
    plt.close()

"""# Dataset download function"""

# Function to download and extract the dataset

def download_and_extract(url, dest_path):
    if not os.path.exists(dest_path):
        os.makedirs(dest_path)

    dataset_zip = os.path.join(dest_path, 'dataset.zip')

    if not os.path.exists(dataset_zip):
        print("Downloading dataset...")
        r = requests.get(url, stream=True)
        with open(dataset_zip, 'wb') as f:
            for chunk in r.iter_content(chunk_size=8192):
                f.write(chunk)
        print("Download complete.")

    if dataset_zip.endswith('.zip'):
        print("Extracting dataset...")
        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:
            zip_ref.extractall(dest_path)
        print("Extraction complete.")

        # Delete the zip file after extraction
        os.remove(dataset_zip)
        print(f"Deleted {dataset_zip} after extraction.")

"""# Model, dataset class and test functions

**UNet model**
"""

#Unet - Full 1024
class UNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(UNet, self).__init__()
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        self.bottleneck = self.conv_block(512, 1024)
        self.upconv4 = self.upconv(1024, 512)
        self.dec4 = self.conv_block(1024, 512)
        self.upconv3 = self.upconv(512, 256)
        self.dec3 = self.conv_block(512, 256)
        self.upconv2 = self.upconv(256, 128)
        self.dec2 = self.conv_block(256, 128)
        self.upconv1 = self.upconv(128, 64)
        self.dec1 = self.conv_block(128, 64)
        self.conv_out = nn.Conv2d(64, out_channels, kernel_size=1)

    def conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def upconv(self, in_channels, out_channels):
        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)

    def forward(self, x):
        enc1 = self.enc1(x)
        enc2 = self.enc2(F.max_pool2d(enc1, 2))
        enc3 = self.enc3(F.max_pool2d(enc2, 2))
        enc4 = self.enc4(F.max_pool2d(enc3, 2))
        bottleneck = self.bottleneck(F.max_pool2d(enc4, 2))
        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.dec4(dec4)
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.dec3(dec3)
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.dec2(dec2)
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.dec1(dec1)
        out = self.conv_out(dec1)
        return out

"""**Model dictionary download function**"""

# Function to download the pretrained model dictionary
def download_dict(base_url, model_dir, filename):
    url = os.path.join(base_url, filename)
    if not os.path.exists(model_dir):
        os.makedirs(model_dir)
    file_path = os.path.join(model_dir, filename)
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad status codes
        with open(file_path, 'wb') as f:
            f.write(response.content)
    except requests.exceptions.RequestException as e:
        print(f"Error downloading the dictionary: {e}")

"""**Data augmentation function**"""

# Function to apply data augmentation

def apply_data_augmentation(image, mask):

    # Convert PyTorch Tensor to PIL Image
    image = TF.to_pil_image(image)
    mask = TF.to_pil_image(mask)

    if data_augmentation_flip:
        # Random horizontal flip
        if random.random() > 0.5:
            image = TF.hflip(image)
            mask = TF.hflip(mask)
        # Random vertical flip
        if random.random() > 0.5:
            image = TF.vflip(image)
            mask = TF.vflip(mask)

    if data_augmentation_rotation:
        # Random rotation
        angle = random.choice([0, 90, 180, 270])
        image = TF.rotate(image, angle)
        mask = TF.rotate(mask, angle)

    if data_augmentation_brightness:
        # Random brightness adjustment
        if random.random() > 0.5:
            factor = random.uniform(0.8, 1.2)
            image = TF.adjust_brightness(image, factor)

    if data_augmentation_contrast:
        # Random contrast adjustment
        if random.random() > 0.5:
            factor = random.uniform(0.8, 1.2)
            image = TF.adjust_contrast(image, factor)

    if data_augmentation_saturation:
        # Random saturation adjustment
        if random.random() > 0.5:
            factor = random.uniform(0.8, 1.2)
            image = TF.adjust_saturation(image, factor)

    if data_augmentation_hue:
        # Random hue adjustment
        if random.random() > 0.5:
            factor = random.uniform(-0.1, 0.1)  # Hue factor is between -0.5 and 0.5
            image = TF.adjust_hue(image, factor)

    if data_augmentation_blur:
        # Random blur
        if random.random() > 0.5:
            image = image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0, 2)))

    if data_augmentation_sharpen:
        # Random sharpening
        if random.random() > 0.5:
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(random.uniform(1.0, 2.0))

    if data_augmentation_gaussian_noise:
        # Add Gaussian noise
        image = np.array(image) / 255.0
        noise = np.random.normal(0, 0.1, image.shape)
        image = np.clip(image + noise, 0, 1)
        image = Image.fromarray((image * 255).astype(np.uint8))

    if data_augmentation_random_padding:
        # Randomly replace part of the image with white or black padding
        if random.random() > 0.5:
            padding_color = random.choice([0, 255])  # Black or white padding
            draw = ImageDraw.Draw(image)
            draw_mask = ImageDraw.Draw(mask)
            width, height = image.size
            pad_width = random.randint(int(width * 0.1), int(width * 0.5))
            pad_height = random.randint(int(height * 0.1), int(height * 0.5))
            x0 = random.randint(0, width - pad_width)
            y0 = random.randint(0, height - pad_height)
            draw.rectangle([x0, y0, x0 + pad_width, y0 + pad_height], fill=padding_color)
            draw_mask.rectangle([x0, y0, x0 + pad_width, y0 + pad_height], fill=0)

    if data_augmentation_random_polygons:
        # Include small white or black polygons randomly within the image
        if random.random() > 0.5:
            polygon_color = random.choice([0, 255])  # Black or white polygons
            draw = ImageDraw.Draw(image)
            draw_mask = ImageDraw.Draw(mask)
            width, height = image.size
            num_polygons = random.randint(1, 5)
            for _ in range(num_polygons):
                shape = random.choice(['square', 'rectangle', 'L'])
                if shape == 'square':
                    size = random.randint(int(min(width, height) * 0.05), int(min(width, height) * 0.2))
                    x0 = random.randint(0, width - size)
                    y0 = random.randint(0, height - size)
                    draw.rectangle([x0, y0, x0 + size, y0 + size], fill=polygon_color)
                    draw_mask.rectangle([x0, y0, x0 + size, y0 + size], fill=0)
                elif shape == 'rectangle':
                    w = random.randint(int(width * 0.05), int(width * 0.2))
                    h = random.randint(int(height * 0.05), int(height * 0.2))
                    x0 = random.randint(0, width - w)
                    y0 = random.randint(0, height - h)
                    draw.rectangle([x0, y0, x0 + w, y0 + h], fill=polygon_color)
                    draw_mask.rectangle([x0, y0, x0 + w, y0 + h], fill=0)
                elif shape == 'L':
                    w = random.randint(int(width * 0.05), int(width * 0.15))
                    h = random.randint(int(height * 0.05), int(height * 0.15))
                    x0 = random.randint(0, width - w * 2)
                    y0 = random.randint(0, height - h * 2)
                    draw.rectangle([x0, y0, x0 + w, y0 + h * 2], fill=polygon_color)
                    draw.rectangle([x0, y0, x0 + w * 2, y0 + h], fill=polygon_color)
                    draw_mask.rectangle([x0, y0, x0 + w, y0 + h * 2], fill=0)
                    draw_mask.rectangle([x0, y0, x0 + w * 2, y0 + h], fill=0)

    # Convert back to PyTorch Tensor
    image = TF.to_tensor(image)
    mask = TF.to_tensor(mask)

    return image, mask

"""**Dataset class**"""

# Define the custom dataset
class SolarPanelTrainDataset(Dataset):
    def __init__(self, image_dir, mask_dir, file_format='bmp', transforms=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.file_format = file_format  # Specify the file format for both images and masks
        self.transforms = transforms
        self.images = os.listdir(image_dir)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.image_dir, img_name)

        # Adjust mask file name to consider the specified format
        mask_name = img_name.replace(f'.{self.file_format}', f'_label.{self.file_format}')
        mask_path = os.path.join(self.mask_dir, mask_name)

        image = Image.open(img_path).convert("RGB")
        mask = Image.open(mask_path).convert("L")
        mask = mask.point(lambda p: p > 80 and 255)

        if self.transforms:
            image = self.transforms(image)
            mask = self.transforms(mask)

            # Apply augmentation to images with solar panels only or all
            apply_augmentation = (not data_augmentation_contain_solar_panel or torch.any(mask > 0)) # Check if the mask contains any pixel value other than 0
            if apply_augmentation:
                image, mask = apply_data_augmentation(image, mask)

        mask = torch.tensor(np.array(mask, dtype=np.uint8), dtype=torch.long)

        # Ensure the mask tensor has the shape (H, W)
        mask = mask.squeeze()

        return image, mask

"""**Train function**"""

def train_model(model_sel, model, lr, early_stop, train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, output_dir, results_path, dataset_name, num_epochs, val_interval, num_samples, image_size, early_stop_patience):

    # Transformations for the dataset
    transform_images = transforms.Compose([
        transforms.Resize((image_size, image_size)),
        transforms.ToTensor(),
    ])

    # Set file_format
    if dataset_name.startswith("PV"):
        file_format = pv_file_format
    else:
        file_format = google_file_format

    # Create datasets
    train_dataset = SolarPanelTrainDataset(image_dir=train_image_dir, mask_dir=train_mask_dir, file_format=file_format, transforms=transform_images)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)
    val_dataset = SolarPanelTrainDataset(image_dir=val_image_dir, mask_dir=val_mask_dir, file_format=file_format, transforms=transform_images)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)

    # Set criterion and optimizer
    if model_sel == "Segformer":
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.AdamW(model.parameters(), lr=lr)
    else:
        criterion = nn.BCEWithLogitsLoss()
        optimizer = optim.Adam(model.parameters(), lr=lr)

    # Train and Validate
    train_losses = []
    train_accuracies = []
    val_losses = []
    val_accuracies = []
    ious = []
    f1s = []

    # Calculate epochs to save samples
    save_epochs = calculate_save_epochs(num_epochs, val_interval, num_samples)

    # Early stop variables
    if early_stop:
        lr_patience = (early_stop_patience - 1) // 2                            # 2:1 ratio for lr patience from early stopping patience parameter
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=lr_patience)
        best_val_loss = float('inf')
        epochs_without_improvement = 0
        optimal_lr = optimizer.param_groups[0]['lr']

    for epoch in range(num_epochs):

        # Training

        model.train()
        running_loss = 0.0
        running_accuracy = 0.0

        # Use tqdm to add a progress bar
        train_loader_tqdm = tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}")

        for batch_idx, (images, masks) in enumerate(train_loader_tqdm):
            images = images.to(device)
            masks = masks.to(device)
            optimizer.zero_grad()

            if model_sel == "Segformer":
                  outputs = model(pixel_values=images).logits
                  outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False) # Upsample the outputs to match the mask size
                  outputs = outputs.permute(0, 2, 3, 1).reshape(-1, outputs.size(1)) # ¡Ensure the outputs and masks have the correct shape (N, C, H, W) -> (N*H*W, C)
                  masks = masks.reshape(-1) # (N, H, W) -> (N*H*W)
                  _, predicted = torch.max(outputs, 1) # Convert outputs to class predictions
                  loss = criterion(outputs, masks.long()) # Ensure target tensor is of type torch.long
                  loss.backward()
                  optimizer.step()
                  running_loss += loss.item()
                  accuracy = accuracy_score(masks.cpu().numpy(), predicted.cpu().numpy())
                  running_accuracy += accuracy
            elif model_sel == "UNet":
                  outputs = model(images)
                  outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False)
                  outputs = outputs.squeeze(1)
                  preds = torch.sigmoid(outputs)
                  predicted = (preds > 0.5).float()
                  loss = criterion(outputs, masks.float())  # BCEWithLogitsLoss requires float
                  loss.backward()
                  optimizer.step()
                  running_loss += loss.item()
                  # Ensure binary targets for accuracy calculation
                  accuracy = accuracy_score(masks.view(-1).cpu().detach().numpy().astype(int), predicted.view(-1).cpu().detach().numpy().astype(int))
                  running_accuracy += accuracy
            else:
                print("Error: Invalid model selection.")

            train_loader_tqdm.set_postfix({"loss":loss.item(), "accuracy":accuracy})

        # Save training samples if the current epoch is in the save_epochs list
        if epoch in save_epochs:
            save_samples(images, masks.reshape(images.shape[0], image_size, image_size), predicted.reshape(images.shape[0], image_size, image_size), epoch, sample_type="train", output_dir=output_dir, num_samples=num_samples)
            print(f"Epoch {epoch+1}/{num_epochs}, Saved training samples")

        # Append metrics
        train_losses.append(running_loss / len(train_loader))
        train_accuracies.append(running_accuracy / len(train_loader))
        print(f"Epoch {epoch+1}/{num_epochs}, Avg Train Loss: {train_losses[-1]}, Avg Train Accuracy: {train_accuracies[-1]}")


        # Validation

        if (epoch + 1) % val_interval == 0: # Execute based on validation interval
            model.eval()
            val_loss = 0.0
            val_accuracy = 0.0
            all_dice_scores = []
            all_jaccard_indices = []

            with torch.no_grad():

                val_loader_tqdm = tqdm(val_loader, desc="Validation")

                for batch_idx, (images, masks) in enumerate(val_loader_tqdm):
                    images = images.to(device)
                    masks = masks.to(device)

                    if model_sel == "Segformer":
                          outputs = model(pixel_values=images).logits
                          outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False) # Upsample the outputs to match the mask size
                          outputs = outputs.permute(0, 2, 3, 1).reshape(-1, outputs.size(1)) # ¡Ensure the outputs and masks have the correct shape (N, C, H, W) -> (N*H*W, C)
                          masks = masks.reshape(-1) # (N, H, W) -> (N*H*W)
                          _, predicted = torch.max(outputs, 1) # Convert outputs to class predictions
                          loss = criterion(outputs, masks.long()) # Ensure target tensor is of type torch.long
                          val_loss += loss.item()
                          # Calculate metrics for the current batch
                          accuracy = accuracy_score(masks.cpu().numpy(), predicted.cpu().numpy())
                          val_accuracy += accuracy
                          dice_score = f1_score(masks.cpu().numpy(), predicted.cpu().numpy(), average='binary', zero_division=0)
                          jaccard_index = jaccard_score(masks.cpu().numpy(), predicted.cpu().numpy(), average='binary', zero_division=0)
                    elif model_sel == "UNet":
                          outputs = model(images)
                          outputs = F.interpolate(outputs, size=(image_size, image_size), mode='bilinear', align_corners=False)
                          outputs = outputs.squeeze(1)
                          preds = torch.sigmoid(outputs)
                          predicted = (preds > 0.5).float()
                          if predicted.shape != masks.shape:
                              predicted = predicted.view(masks.shape[0], masks.shape[1], masks.shape[2])
                          loss = criterion(outputs, masks.float())  # BCEWithLogitsLoss requires float
                          val_loss += loss.item()
                          # Calculate metrics for the current batch
                          accuracy = accuracy_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy())
                          val_accuracy += accuracy
                          dice_score = f1_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy(), average='binary', zero_division=0)
                          jaccard_index = jaccard_score(masks.view(-1).cpu().numpy(), predicted.view(-1).cpu().numpy(), average='binary', zero_division=0)
                    else:
                        print("Error: Invalid model selection.")

                    # Append metrics
                    all_dice_scores.append(dice_score)
                    all_jaccard_indices.append(jaccard_index)

                    val_loader_tqdm.set_postfix({"loss": loss.item(), "accuracy": accuracy, "f1-score": dice_score, "jaccard-index": jaccard_index})

            # Save validation samples if the current epoch is in the save_epochs list
            if epoch in save_epochs:
                save_samples(images, masks.reshape(images.shape[0], image_size, image_size), predicted.reshape(images.shape[0], image_size, image_size), epoch, sample_type="val", output_dir=output_dir, num_samples=num_samples)
                print(f"Epoch {epoch+1}/{num_epochs}, Saved validation samples")

            # Append metrics
            val_losses.append(val_loss / len(val_loader))
            val_accuracies.append(val_accuracy / len(val_loader))
            avg_dice_score = sum(all_dice_scores) / len(all_dice_scores)
            avg_jaccard_index = sum(all_jaccard_indices) / len(all_jaccard_indices)

            print(f"Epoch {epoch+1}/{num_epochs}")
            print(f"Validation: Avg Train Loss: {train_losses[-1]:.4f}, Avg Val Loss: {val_losses[-1]:.4f}")
            print(f"Validation: Avg Train Accuracy: {train_accuracies[-1]:.4f}, Avg Val Accuracy: {val_accuracies[-1]:.4f}")
            print(f"Validation: Avg Dice Score: {avg_dice_score:.4f}, Avg Jaccard Index: {avg_jaccard_index:.4f}")

            ious.append(avg_jaccard_index)
            f1s.append(avg_dice_score)

            # Early Stop Check
            if early_stop:
                if val_loss < best_val_loss:
                    best_val_loss = val_loss
                    print(f"Best validation loss so far: {best_val_loss:.4f}")
                    epochs_without_improvement = 0
                    optimal_lr = optimizer.param_groups[0]['lr']
                else:
                    epochs_without_improvement += 1
                    if epochs_without_improvement >= early_stop_patience:
                        print(f"Early stopping triggered at epoch {epoch+1}")
                        print(f"Optimal learning rate identified: {optimal_lr:.8f}")
                        break

                # Step the scheduler based on the validation loss
                if len(val_losses) > 0:
                    scheduler.step(val_losses[-1])

                    # Print scheduler's learning rate adjustment
                    current_lr = optimizer.param_groups[0]['lr']
                    print(f"Scheduler step: Learning rate is now {current_lr:.8f}")

    # Save and show the final plots at the end of training
    plot_charts(train_losses, train_accuracies, val_losses, val_accuracies, ious, f1s, val_interval)
    save_plots(train_losses, train_accuracies, val_losses, val_accuracies, ious, f1s, val_interval, epoch=None, output_dir=output_dir)
    print(f"Saved final plots")

    return {'train_losses':train_losses, 'train_accuracies':train_accuracies,
            'val_losses':val_losses, 'val_accuracies':val_accuracies,
            'ious':ious, 'f1s':f1s}

"""# Execution

**Download dataset**
"""

# Download and extract the dataset
start_time = time.perf_counter()
download_and_extract(dataset_url, dataset_path)
train_images_count = len(os.listdir(train_image_dir))                           # Count the number of images under train folder
val_images_count = len(os.listdir(val_image_dir))                               # Count the number of images under validation folder
print(f"Number of images in the train set: {train_images_count}")
print(f"Number of images in the validation set: {val_images_count}")
elapsed_time = time.perf_counter() - start_time
print(f"Download & extract took: {format_time(elapsed_time)}")

"""**Load the model**"""

# Load selected model
if model_sel == "Segformer":
    print("Loading Segformer...")
    # Load the pretrained Segformer model
    model = SegformerForSemanticSegmentation.from_pretrained(
        seg_pretrained_model_name,
        num_labels=num_labels,
        id2label=id2label,
        label2id=label2id,
        ignore_mismatched_sizes=True,
    )
elif model_sel == "UNet":
    print("Loading UNet...")
    # Load the pretrained UNet model
    model = UNet(in_channels=3, out_channels=1)
else:
    print("Error: Invalid model selection")

# Download and load the state dictionary from a pretrained model
if dict_sel is not None:
    download_dict(dict_location, model_dir, dict_sel)
    pretrained_model_path = model_dir + dict_sel
    try:
        model.load_state_dict(torch.load(pretrained_model_path))
        print(f"Successfully loaded the model from {pretrained_model_path}")
    except Exception as e:
        print(f"Error loading the model from {pretrained_model_path}: {e}")

# Move model to GPU if available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

"""**Run training and validation**"""

# Run training and validation
start_time = time.perf_counter()
print(f"Running test")
model_train_log = train_model(model_sel, model, lr, early_stop, train_image_dir, train_mask_dir, val_image_dir, val_mask_dir, output_dir, results_path, dataset_name, num_epochs, val_interval, num_samples, image_size, early_stop_patience)
# Save the model
def save_model(model, model_dir, model_name):
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, model_name)
    torch.save(model.state_dict(), model_path)
    print(f"Saved model at {model_path}")
save_model(model, output_dir, model_name)
elapsed_time = time.perf_counter() - start_time
print(f"Training and validation took: {format_time(elapsed_time)}\n")

"""**Zip results**"""

# Create the zip file
zip_dir(root_dir, zip_filename, exclude_folders)
zip_file_path = os.path.join(root_dir, zip_filename)
list_folders_and_files_in_zip(zip_file_path)